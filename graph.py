import os
import json
from typing import List, TypedDict
from langchain_core.prompts import ChatPromptTemplate
from datetime import datetime
from langchain_core.output_parsers import StrOutputParser
from langchain_google_genai import ChatGoogleGenerativeAI
from langgraph.graph import StateGraph, END
from dotenv import load_dotenv

from paperless_client import PaperlessClient
from vector_db import semantic_search

load_dotenv()


class GraphState(TypedDict):
    """Estado do grafo LangGraph para RAG com Paperless-NGX."""
    question: str
    search_query: str
    documents: List[dict]
    generation: str
    error: str


# Inicializa o cliente Paperless e LLM
paperless_client = PaperlessClient()

gemini_api_key = os.getenv("GEMINI_API_KEY")
if not gemini_api_key:
    raise ValueError("GEMINI_API_KEY n√£o encontrada no arquivo .env")

llm = ChatGoogleGenerativeAI(
    model="gemini-2.5-flash",
    google_api_key=gemini_api_key,
    convert_system_message_to_human=True,
    temperature=0.3
)


# ============================================================================
# PROMPTS OTIMIZADOS
# ============================================================================

QUERY_TRANSFORM_PROMPT = ChatPromptTemplate.from_template(
    """Voc√™ √© um especialista em otimiza√ß√£o de buscas. Sua tarefa √© extrair APENAS os 3-5 TERMOS MAIS IMPORTANTES de uma pergunta para busca em documentos.

REGRAS CR√çTICAS:
1. Extraia APENAS 3-5 termos essenciais (no m√°ximo 5!)
2. Priorize: nomes pr√≥prios, conceitos-chave, termos t√©cnicos
3. REMOVA: palavras comuns, artigos, preposi√ß√µes, verbos auxiliares
4. Se houver express√£o t√©cnica/nome pr√≥prio, mantenha completa (ex: "Tarifa Zero", "IPTU")
5. Prefira termos que REALMENTE aparecem em documentos formais

ESTRAT√âGIA:
- Identifique o CONCEITO PRINCIPAL da pergunta
- Adicione 1-2 sin√¥nimos OU termos de contexto direto
- PARE! N√£o adicione mais nada

EXEMPLOS:

Pergunta: "O que √© a Tarifa Zero?"
Query: Tarifa Zero transporte gratuito
Explica√ß√£o: "Tarifa Zero" √© o termo principal, "transporte" e "gratuito" s√£o contexto direto

Pergunta: "Quais s√£o os procedimentos do regime jur√≠dico das parcerias?"
Query: regime jur√≠dico parcerias procedimentos
Explica√ß√£o: 3 termos principais que definem o assunto

Pergunta: "Como funciona a cobran√ßa de IPTU?"
Query: IPTU cobran√ßa imposto predial
Explica√ß√£o: IPTU √© o termo principal, "cobran√ßa" √© a a√ß√£o, "imposto predial" √© contexto

Pergunta: "Quais os tributos de compet√™ncia municipal?"
Query: tributos municipais compet√™ncia
Explica√ß√£o: Termos essenciais sem redund√¢ncia

Pergunta: "O que diz a lei sobre licita√ß√µes?"
Query: licita√ß√µes lei processo licitat√≥rio
Explica√ß√£o: Termos-chave do universo de licita√ß√µes

AGORA √â SUA VEZ:
Pergunta: "{question}"

Query otimizada (APENAS 3-5 termos essenciais, separados por espa√ßo):"""
)


RAG_GENERATION_PROMPT = ChatPromptTemplate.from_template(
    """Voc√™ √© um assistente jur√≠dico especializado em legisla√ß√£o e documentos administrativos brasileiros.
Sua miss√£o √© fornecer respostas COMPLETAS, DETALHADAS e BEM FUNDAMENTADAS usando EXCLUSIVAMENTE os documentos fornecidos.

INSTRU√á√ïES CR√çTICAS:

1. **LEIA TODO O CONTE√öDO DOS DOCUMENTOS** antes de responder
   - N√£o resuma demais - use todas as informa√ß√µes relevantes dispon√≠veis
   - Extraia TODOS os detalhes pertinentes √† pergunta

2. **ESTRUTURE A RESPOSTA DE FORMA COMPLETA:**
   - Comece com uma introdu√ß√£o clara do que foi encontrado
   - Desenvolva todos os pontos importantes com detalhes
   - Se houver artigos, incisos, par√°grafos: CITE-OS NA √çNTEGRA ou resuma seu conte√∫do
   - Se houver listas, procedimentos, requisitos: ENUMERE TODOS
   - Se houver defini√ß√µes: TRANSCREVA ou par√°frase completamente

3. **CITA√á√ïES OBRIGAT√ìRIAS:**
   - Cite a fonte ap√≥s CADA informa√ß√£o importante: [Nome do Documento](link)
   - Use cita√ß√µes diretas quando o texto legal for relevante

4. **CITA√á√ÉO DA BASE TEXTUAL :**
   - Ao final de cada par√°grafo ou se√ß√£o que resume uma informa√ß√£o, inclua um bloco de cita√ß√£o com o trecho exato do documento que serviu de base.
   - Formate assim:
     > "Trecho literal do documento que comprova a informa√ß√£o..." [Nome do Documento](link)

5. **FORMATA√á√ÉO PARA M√ÅXIMA CLAREZA:**
   - Use **negrito** para termos-chave e t√≠tulos de se√ß√µes
   - Use listas numeradas para procedimentos/etapas
   - Use bullet points para requisitos/caracter√≠sticas
   - Use blocos de cita√ß√£o (>) para transcri√ß√µes literais importantes

6. **COMPLETUDE √â ESSENCIAL:**
   - Se o documento tem 10 procedimentos, liste os 10
   - Se h√° requisitos, prazos, penalidades: inclua TODOS
   - N√£o diga apenas "o documento menciona X" - EXPLIQUE o que o documento diz sobre X

7. **SE N√ÉO HOUVER INFORMA√á√ÉO SUFICIENTE:**
   - Seja expl√≠cito: "Os documentos mencionam [X], mas n√£o detalham [Y]"
   - Indique o que foi encontrado e o que est√° ausente

---
DOCUMENTOS PARA VISUALIZA√á√ÉO (PREVIEW):
{preview_links}
---

DOCUMENTOS DISPON√çVEIS (CONTE√öDO COMPLETO PARA SUA AN√ÅLISE):
{context}

---
PERGUNTA DO USU√ÅRIO:
{question}

RESPOSTA DETALHADA E COMPLETA (com todas as cita√ß√µes necess√°rias):"""
)


RELEVANCE_RANKING_PROMPT = ChatPromptTemplate.from_template(
    """Voc√™ √© um especialista em an√°lise de relev√¢ncia. Sua tarefa √© analisar uma lista de documentos e determinar quais s√£o relevantes para responder a uma pergunta, e ent√£o ranke√°-los.

PERGUNTA DO USU√ÅRIO:
{question}

DOCUMENTOS DISPON√çVEIS:
{context}

INSTRU√á√ïES:
1. Leia a pergunta e o conte√∫do de cada documento.
2. Determine quais documentos s√£o **realmente √∫teis** para formular uma resposta completa.
3. Retorne uma lista Python com os **n√∫meros** dos documentos relevantes, ordenados do **mais importante para o menos importante**.

REGRAS DE SA√çDA:
- Sua resposta deve ser APENAS a lista de n√∫meros. Exemplo: `[3, 1]`
- Se o Documento 3 for o mais relevante e o Documento 1 for o segundo mais relevante, sua resposta ser√° `[3, 1]`.
- Se nenhum documento for relevante, retorne uma lista vazia: `[]`

LISTA DE RELEV√ÇNCIA (APENAS N√öMEROS):"""
)


# ============================================================================
# NODOS DO GRAFO
# ============================================================================


def retrieve(state: GraphState) -> GraphState:
    """Recupera documentos relevantes do Paperless-NGX com estrat√©gia multi-tentativa."""
    print("\nüìö RECUPERANDO DOCUMENTOS (BUSCA SEM√ÇNTICA)...")
    # Usa a pergunta original do usu√°rio diretamente para a busca sem√¢ntica
    search_query = state["question"]
    
    try:
        # 1. Realiza a busca sem√¢ntica no banco de dados vetorial
        similar_docs = semantic_search(search_query, limit=7)

        if not similar_docs:
            print("   ‚ùå Nenhum documento encontrado na busca sem√¢ntica.")
            return {"documents": []}

        # 2. Recupera o conte√∫do completo de cada documento do Paperless
        print("\n   üîÑ Buscando conte√∫do completo dos documentos encontrados...")
        full_documents = []
        for doc_info in similar_docs:
            paperless_id = doc_info['paperless_id']
            full_doc = paperless_client.get_document_metadata(paperless_id)
            if full_doc:
                # Adiciona o score de similaridade e links do DB para o objeto completo
                full_doc['score'] = doc_info.get('similarity', 0)
                full_doc['link'] = doc_info.get('preview_link') # Garante o link correto
                full_documents.append(full_doc)
                print(f"      ‚úÖ Conte√∫do completo para '{full_doc['title']}' (ID: {paperless_id}) obtido.")
            else:
                print(f"      ‚ö†Ô∏è Falha ao obter conte√∫do completo para o ID: {paperless_id}")

        return {"documents": full_documents}
        
    except Exception as e:
        print(f"   ‚ùå Erro na recupera√ß√£o: {e}")
        return {"documents": [], "error": str(e)}


def check_relevance(state: GraphState) -> GraphState:
    """Verifica se os documentos encontrados s√£o relevantes para a pergunta."""
    print("\nüéØ VERIFICANDO RELEV√ÇNCIA...")
    question = state["question"]
    documents = state["documents"]
    
    if not documents:
        return state
    
    # Prepara preview dos documentos
    context_preview = ""
    for i, doc in enumerate(documents, 1):  # Analisa at√© 5 documentos
        content = doc.get("highlights") or doc.get("content", "")
        if content:
            preview = content[:2000] if len(content) > 2000 else content
            context_preview += f"--- DOCUMENTO {i} ---\nT√≠tulo: {doc['title']}\nConte√∫do: {preview}...\n\n"
    
    try:
        relevance_ranker = RELEVANCE_RANKING_PROMPT | llm | StrOutputParser()
        ranking_str = relevance_ranker.invoke({
            "context": context_preview,
            "question": question
        }).strip()
        
        print(f"   üìä An√°lise de relev√¢ncia retornou: {ranking_str}")
        
        # Tenta avaliar a string como uma lista Python
        try:
            ranked_indices = json.loads(ranking_str)
            if not isinstance(ranked_indices, list):
                raise ValueError("N√£o √© uma lista")
        except (json.JSONDecodeError, ValueError):
            print("   ‚ö†Ô∏è N√£o foi poss√≠vel decodificar o ranking, mantendo a ordem original.")
            return state

        if not ranked_indices:
            print("   üóëÔ∏è Nenhum documento considerado relevante. Descartando todos.")
            return {"documents": []}

        # Filtra e reordena os documentos com base no ranking
        ranked_docs = []
        for index in ranked_indices:
            if 1 <= index <= len(documents):
                ranked_docs.append(documents[index - 1])
        
        print(f"   ‚úÖ Documentos filtrados e reordenados. {len(ranked_docs)} mantidos.")
        return {"documents": ranked_docs}
        
    except Exception as e:
        print(f"   ‚ö†Ô∏è Erro na verifica√ß√£o: {e}")
        return state  # Continua com os documentos em caso de erro


def generate(state: GraphState) -> GraphState:
    """Gera a resposta usando o LLM com base nos documentos."""
    print("\n‚úçÔ∏è GERANDO RESPOSTA...")
    question = state["question"]
    documents = state["documents"]
    
    if not documents:
        return {
            "generation": "‚ùå **N√£o encontrei documentos relevantes no sistema para responder sua pergunta.**\n\n"
                         "üí° **Sugest√µes:**\n"
                         "- Tente usar termos diferentes ou mais espec√≠ficos\n"
                         "- Verifique se h√° documentos sobre esse assunto no Paperless\n"
                         "- Reformule a pergunta de forma mais direta"
        }
    
    # Formata contexto estruturado com TODO O CONTE√öDO
    context_parts = []
    preview_links_parts = []
    for i, doc in enumerate(documents, 1):
        # Prioriza highlights, mas pega TODO o conte√∫do dispon√≠vel
        content = doc.get("content", "") or doc.get("highlights", "")
        
        if content:
            # SEM LIMITE - envia todo o conte√∫do do documento
            score_info = f"Relev√¢ncia: {doc.get('score', 0):.2%}" if doc.get('score') else ""
            
            context_parts.append(
                f"=== DOCUMENTO {i} ===\n"
                f"T√≠tulo: {doc['title']}\n"
                f"Link: {doc['link']}\n"
                f"{score_info}\n"
                f"Conte√∫do COMPLETO:\n{content}\n"
            )
            
            print(f"   üìÑ Doc {i}: {doc['title'][:50]}... ({len(content):,} caracteres)")
            
            preview_links_parts.append(f"- [{doc['title']}]({doc['link']})")
    
    context = "\n\n".join(context_parts)
    preview_links = "\n".join(preview_links_parts)

    print(f"\n   üìä ESTAT√çSTICAS DO CONTEXTO:")
    print(f"   ‚Ä¢ Total de caracteres: {len(context):,}")
    print(f"   ‚Ä¢ N√∫mero de documentos: {len(documents)}")
    print(f"   ‚Ä¢ Tamanho m√©dio por documento: {len(context)//len(documents):,} caracteres")
    print(f"   ‚Ä¢ Tokens estimados: ~{len(context)//4:,} tokens")
    
    # # DEBUG: Mostra preview mais longo do contexto
    # print("\n" + "=" * 70)
    # print("üîç PREVIEW DO CONTEXTO ENVIADO PARA A LLM:")
    # print("=" * 70)
    
    # # Mostra primeiros 2000 caracteres de cada documento
    # for i, part in enumerate(context_parts, 1):
    #     lines = part.split('\n')
    #     preview_lines = []
    #     char_count = 0
        
    #     for line in lines:
    #         if char_count + len(line) > 2000:
    #             preview_lines.append(f"\n... [DOCUMENTO CONTINUA POR MAIS {len(part) - char_count:,} CARACTERES] ...")
    #             break
    #         preview_lines.append(line)
    #         char_count += len(line)
        
    #     print(f"\n--- DOCUMENTO {i} ---")
    #     print('\n'.join(preview_lines))
    
    # print("\n" + "=" * 70)
    # print(f"üìù PERGUNTA ENVIADA: {question}")
    # print("=" * 70 + "\n")
    
    try:
        rag_chain = RAG_GENERATION_PROMPT | llm | StrOutputParser()
        generation = rag_chain.invoke({
            "context": context,
            "question": question,
            "preview_links": preview_links
        })
        
        print("   ‚úÖ Resposta gerada com sucesso")
        print(f"   üìè Tamanho da resposta: {len(generation)} caracteres")
        return {"generation": generation}
        
    except Exception as e:
        print(f"   ‚ùå Erro na gera√ß√£o: {e}")
        return {
            "generation": "Desculpe, ocorreu um erro ao processar os documentos.",
            "error": str(e)
        }


# ============================================================================
# CONSTRU√á√ÉO DO GRAFO
# ============================================================================

def build_rag_graph() -> StateGraph:
    """Constr√≥i e compila o grafo RAG."""
    workflow = StateGraph(GraphState)
    
    workflow.add_node("retrieve", retrieve)
    workflow.add_node("check_relevance", check_relevance)
    workflow.add_node("generate", generate)
    
    # O ponto de entrada agora √© a recupera√ß√£o (retrieve)
    workflow.set_entry_point("retrieve")
    workflow.add_edge("retrieve", "check_relevance")
    workflow.add_edge("check_relevance", "generate")
    workflow.add_edge("generate", END)
    
    return workflow.compile()


app = build_rag_graph()


# ============================================================================
# TESTE COM NOVAS PERGUNTAS
# ============================================================================

# if __name__ == "__main__":
#     print("=" * 70)
#     print("üß™ TESTANDO WORKFLOW RAG COM PAPERLESS-NGX")
#     print("=" * 70)
    
#     # NOVAS PERGUNTAS DE TESTE
#     test_questions = [
#         "Explique o c√≥digo de conduta para servidores?",
#         "Quais s√£o os procedimentos do regime jur√≠dico das parcerias?",
#     ]
    
#     for question in test_questions:
#         print(f"\n\n{'=' * 70}")
#         print(f"‚ùì PERGUNTA: {question}")
#         print("=" * 70)
        
#         try:
#             final_state = app.invoke({"question": question})
            
#             print("\n" + "=" * 70)
#             print("üìù RESPOSTA FINAL:")
#             print("=" * 70)
#             print(final_state.get("generation", "Nenhuma resposta gerada"))
            
#             documents = final_state.get("documents", [])
#             if documents:
#                 print("\n" + "=" * 70)
#                 print("üìö FONTES UTILIZADAS:")
#                 print("=" * 70)
#                 for i, doc in enumerate(documents, 1):
#                     score = doc.get('score', 0)
#                     print(f"{i}. [{doc['title']}]({doc['link']}) - Score: {score:.2%}")
            
#             if final_state.get("error"):
#                 print(f"\n‚ö†Ô∏è Aviso: {final_state['error']}")
                
#         except Exception as e:
#             print(f"\n‚ùå ERRO: {e}")
#             import traceback
#             traceback.print_exc()
        
#         print("\n" + "=" * 70 + "\n")